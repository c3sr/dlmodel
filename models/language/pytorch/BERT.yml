name: BERT
framework:
  name: PyTorch
  version: 1.8.1
version: 1.0
description: >
  MLPerf_BERT.
references:
  - https://github.com/mlcommons/inference/tree/master/language/bert
  - https://zenodo.org/record/3733896
license: Apache License, Version 2.0
modality: general
inputs:
    - type: general
      description: input id
      parameters:
          element_type: int64
    - type: general
      description: input mask
      parameters:
          element_type: int64
    - type: general
      description: segment id
      parameters:
          element_type: int64
outputs:
    - type: general
      description: start position to the answer
      parameters:
        element_type: int64
    - type: general
      description: end position to the answe
      parameters:
        element_type: int64
model:
    is_archive:
        false
    graph_path: https://s3.amazonaws.com/store.carml.org/models/pytorch/bert_gpu.pt
    graph_checksum: e75cdc57d736badc252f639602878e9c
preprocess: |
  def preprocess(ctx, data):
    import numpy as np
    cur = eval_features[int(data)]
    return np.array(cur.input_ids, dtype = np.int64), np.array(cur.input_mask, dtype = np.int64), np.array(cur.segment_ids, dtype = np.int64)
postprocess: |
  def postprocess(ctx, data):
    import numpy as np
    import json
    res = np.stack([data[0], data[1]], axis = -1).squeeze(0).tolist()
    return [json.dumps(res)]
attributes:
    kind: Transformer
    manifest_author: Yen-Hsiang Chang

