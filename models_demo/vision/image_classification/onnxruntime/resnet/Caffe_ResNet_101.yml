name: Caffe_ResNet_101 # name of your model
framework:
  name: Onnxruntime # framework for the model
  version: 1.7.1 # framework version constraint
version: 1.0 # version information in semantic version format
description: >
  This model is a replication of the model described in the Resnet publication originally written in Caffe.
  The pre-trained model expects input in mini-batches of 3-channel BGR images of shape (3 x H x W), where H and W are expected to be 224. The images have to be loaded in to a range of [0, 255] and then normalized using mean = [102.9801, 115.9465, 122.7717] and std = [1, 1, 1].
references: # references to papers / websites / etc.. describing the model
  - https://github.com/Cadene/pretrained-models.pytorch#reproducing-results
  - https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/models/cafferesnet.py
  - https://github.com/KaimingHe/deep-residual-networks
# license of the model
license: BSD 3-Clause License
# inputs to the model
modality: image_classification
inputs:
  - type: image
    # description of the first input
    description: the input image
    parameters: # type parameters
      element_type: float32
      input_layer: 0
      layout: CHW
      color_mode: RGB
      dimensions: [3, 224, 224]
      mean: [102.9801, 115.9465, 122.7717]
      scale: [1, 1, 1]
outputs:
  - type: classification
    description: the probability
    parameters:
      element_type: float32
model: # specifies model graph and weights resources
  is_archive:
    false # if set, then the base_url is a url to an archive
    # the graph_path and weights_path then denote the
    # file names of the graph and weights within the archive
  graph_path: https://s3.amazonaws.com/store.carml.org/models/onnxruntime/cafferesnet101-imagenet.onnx
  graph_checksum: 9f029061ed3b841cb8bf35faa72ba9ef
  features_path: http://s3.amazonaws.com/store.carml.org/synsets/imagenet/synset.txt
  features_checksum: 4d234b5833aca44928065a180db3016a
preprocess: |
  from torchvision import transforms
  from PIL import Image
  preprocessor = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[102.9801 / 255, 115.9465 / 255, 122.7717 / 255], std=[1 / 255, 1 / 255, 1 / 255])
  ])
  def preprocess(ctx, data):
    img = Image.open(dataset[int(data)]).convert('RGB')
    return preprocessor(img).numpy()
postprocess: |
  from scipy.special import softmax
  def postprocess(ctx, data):
    return softmax(data[0], axis = 1).tolist()
attributes: # extra network attributes
  kind: CNN # the kind of neural network (CNN, RNN, ...)
  training_dataset: ImageNet # dataset used to for training
  manifest_author: Yen-Hsiang Chang
