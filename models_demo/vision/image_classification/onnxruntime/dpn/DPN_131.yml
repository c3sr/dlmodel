name: DPN_131
framework:
  name: Onnxruntime
  version: 1.7.1
version: 1.0
description: >
  This model is a replication of the model described in the Dual Path Networks publication.
  The pre-trained model expects input in mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [124 / 255, 117 / 255, 104 / 255] and std = [1 / (.0167 * 255), 1 / (.0167 * 255), 1 / (.0167 * 255)].
references:
  - https://github.com/Cadene/pretrained-models.pytorc
  - https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/models/dpn.py
  - https://github.com/cypw/DPNs
  - https://github.com/oyam/pytorch-DPNs
license: BSD 3-Clause License
modality: image_classification
inputs:
  - type: image
    description: the input image
    parameters:
      element_type: float32
      input_layer: 0
      layout: CHW
      color_mode: RGB
      dimensions: [3, 224, 224]
      mean: [124, 117, 104]
      scale: [59.88, 59.88, 59.88]
outputs:
  - type: classification
    description: the probability
    parameters:
      element_type: float32
model:
  is_archive:
    false
  graph_path: https://s3.amazonaws.com/store.carml.org/models/onnxruntime/dpn131-imagenet.onnx
  graph_checksum: ce7898dd8858a699e1a22cf784e9d5e2
  features_path: http://s3.amazonaws.com/store.carml.org/synsets/imagenet/synset.txt
  features_checksum: 4d234b5833aca44928065a180db3016a
preprocess: |
  from torchvision import transforms
  from PIL import Image
  preprocessor = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[124 / 255, 117 / 255, 104 / 255], std=[59.88 / 255, 59.88 / 255, 59.88 / 255])
  ])
  def preprocess(ctx, data):
    img = Image.open(dataset[int(data)]).convert('RGB')
    return preprocessor(img).numpy()
postprocess: |
  from scipy.special import softmax
  def postprocess(ctx, data):
    return softmax(data[0], axis = 1).tolist()
attributes:
  kind: CNN
  training_dataset: ImageNet
  manifest_author: Yen-Hsiang Chang
