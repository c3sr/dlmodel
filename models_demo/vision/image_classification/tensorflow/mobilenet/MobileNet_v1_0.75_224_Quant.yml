name: MobileNet_v1_0.75_224_Quant
framework:
  name: TensorFlow
  version: 1.14.0
version: 1.0
description: >
  MobileNet is a general architecture and can be used for multiple use cases.
  Depending on the use case, it can use different input layer size and different width factors.
  This allows different width models to reduce the number of multiply-adds and thereby reduce inference cost on mobile devices.
references:
  - https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md
  - http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.75_224_quant.tgz
  - https://arxiv.org/pdf/1704.04861.pdf
  - https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet.py
license: Apache License, Version 2.0
modality: image_classification
inputs:
  - type: image
    description: the input image
    parameters:
      element_type: float32
      input_layer: input
      layout: HWC
      color_mode: RGB
      dimensions: [3, 224, 224]
      mean: [128, 128, 128]
      scale: 128
outputs:
  - type: classification
    description: the probability
    parameters:
      element_type: float32
      output_layer: MobilenetV1/Predictions/Reshape_1
model:
  base_url: https://s3.amazonaws.com/store.carml.org/models/tensorflow/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.75_224_quant.tgz
  graph_checksum: 2f809f0ee6e09409b65c8fd87034c245
  is_archive:
    true
  graph_path: mobilenet_v1_0.75_224_quant_frozen.pb
  features_path: https://s3.amazonaws.com/store.carml.org/synsets/imagenet/synset1.txt
  features_checksum: 6c05083991207dea5c37f2d271014fad
preprocess: |
  import numpy as np
  import cv2
  def center_crop(img, out_height, out_width):
    height, width, _ = img.shape
    left = int((width - out_width) / 2)
    right = int((width + out_width) / 2)
    top = int((height - out_height) / 2)
    bottom = int((height + out_height) / 2)
    img = img[top:bottom, left:right]
    return img
  def resize_with_aspectratio(img, out_height, out_width, scale=87.5, inter_pol=cv2.INTER_LINEAR):
    height, width, _ = img.shape
    new_height = int(100. * out_height / scale)
    new_width = int(100. * out_width / scale)
    if height > width:
      w = new_width
      h = int(new_height * height / width)
    else:
      h = new_height
      w = int(new_width * width / height)
    img = cv2.resize(img, (w, h), interpolation=inter_pol)
    return img
  def preprocess_image(img, dims=None, need_transpose=False):
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    output_height, output_width, _ = dims
    cv2_interpol = cv2.INTER_AREA
    img = resize_with_aspectratio(img, output_height, output_width, inter_pol=cv2_interpol)
    img = center_crop(img, output_height, output_width)
    img = np.asarray(img, dtype='float32')
    means = np.array([128, 128, 128])
    img -= means
    scale = 128
    img /= scale
    if need_transpose:
      img = img.transpose([2, 0, 1])
    return img
  def preprocess(ctx, data):
    img = cv2.imread(dataset[int(data)])
    return preprocess_image(img, [224, 224, 3], False)
postprocess: |
  def postprocess(ctx, data):
    return data[0].tolist()
attributes:
  kind: CNN
  training_dataset: ImageNet
  manifest_author: Yen-Hsiang Chang
