name: TorchVision_FCN_Resnet_101
framework:
  name: Onnxruntime
  version: 1.7.1
version: 1.0
description: >
  The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].
references:
  - https://arxiv.org/pdf/1411.4038.pdf
  - https://github.com/pytorch/vision/blob/v0.4.0/torchvision/models/segmentation/fcn.py
  - https://pytorch.org/docs/stable/torchvision/models.html
license: BSD 3-Clause License
modality: image_semantic_segmentation
inputs:
  - type: image
    description: the input image
    parameters:
      element_type: float32
      input_layer: 0
      layout: CHW
      color_mode: RGB
      mean: [123.675, 116.280, 103.530]
      scale: [58.395, 57.120, 57.375]  
outputs:
  - type: semanticsegment
    description: the output semantic segment
    parameters:
      element_type: int64
model:
  is_archive:
    false
  graph_path: https://s3.amazonaws.com/store.carml.org/models/onnxruntime/torchvision_fcn_resnet101.onnx
  graph_checksum: 4b24503a089adba2d10b296adf760c87
  features_path: https://s3.amazonaws.com/store.carml.org/models/tensorflow/models/deeplabv3_mnv2_pascal_train_aug_2018_01_29/pascal-voc-classes.txt
  features_checksum: 9ce439bcfb44c304e49a0fe1ae398f69
preprocess: |
  from torchvision import transforms
  from PIL import Image
  preprocessor = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
  ])
  def preprocess(ctx, data):
    img = Image.open(dataset[int(data)]).convert('RGB')
    return preprocessor(img).numpy()
postprocess: |
  import numpy as np
  def postprocess(ctx, data):
    return np.argmax(data[0], axis = 1).tolist()
attributes:
  kind: CNN
  training_dataset: COCO 2017
  manifest_author: Yen-Hsiang Chang
