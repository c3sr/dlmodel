name: OnnxVision_SSD
framework:
  name: Onnxruntime
  version: 1.7.1
version: 1.0
description: >
  This model is the Single Stage Detector in onnx vision
  All pre-trained models expect input images normalized in the same way, i.e. 3-channel RGB images of shape (3 x H x W), where H and W are expected to be 1200. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]
  This model only allows batchsize = 1 currently.
references:
  - https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/ssd
license: Apache-2.0 License
modality: image_object_detection
inputs:
  - type: image
    description: the input image
    parameters:
      element_type: float32
      input_layer: 0
      layout: CHW
      color_mode: RGB
      dimensions: [3, 1200, 1200]
      mean: [123.675, 116.280, 103.530]
      scale: [58.395, 57.120, 57.375]  
outputs:
  - type: boundingboxes
    description: boundingboxes
    parameters:
      element_type: float32
  - type: classes
    description: classes
    parameters:
      element_type: float32
  - type: scores
    description: scores
    parameters:
      element_type: float32
model:
    is_archive:
      false
    graph_path: https://s3.amazonaws.com/store.carml.org/models/onnxruntime/onnxvision_ssd.onnx
    graph_checksum: c87961aa865330bbb6eab9687ae2496c
    features_path: https://s3.amazonaws.com/store.carml.org/synsets/coco/coco_labels_2014_2017_background.txt
    features_checksum: e7103a997c945e0f87c49a03c9c56a1b
preprocess: |
  from torchvision import transforms
  from PIL import Image
  preprocessor = transforms.Compose([
    transforms.Resize((1200, 1200)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
  ])
  def preprocess(ctx, data):
    img = Image.open(dataset[int(data)]).convert('RGB')
    return preprocessor(img).numpy()
postprocess: |
  def postprocess(ctx, data):
    probs, labels, boxes = [], [], []
    for i in range(len(data[0])):
      cur_probs, cur_labels, cur_boxes = [], [], []
      for j in range(len(data[0][i])):
        prob, label, box = data[2][i][j], data[1][i][j], data[0][i][j].tolist()
        box = [box[1], box[0], box[3], box[2]]
        cur_probs.append(prob)
        cur_labels.append(label)
        cur_boxes.append(box)
      probs.append(cur_probs)
      labels.append(cur_labels)
      boxes.append(cur_boxes)
    return probs, labels, boxes
attributes:
  kind: CNN
  training_dataset: COCO
  manifest_author: Yen-Hsiang Chang
