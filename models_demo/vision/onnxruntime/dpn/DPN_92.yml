name: DPN_92 # name of your model
framework:
  name: Onnxruntime # framework for the model
  version: 1.7.1 # framework version constraint
version: 1.0 # version information in semantic version format
description: >
  This model is a replication of the model described in the Dual Path Networks publication.
  The pre-trained model expects input in mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [124 / 255, 117 / 255, 104 / 255] and std = [1 / (.0167 * 255), 1 / (.0167 * 255), 1 / (.0167 * 255)].
references: # references to papers / websites / etc.. describing the model
  - https://github.com/Cadene/pretrained-models.pytorch#reproducing-results
  - https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/models/dpn.py
  - https://github.com/cypw/DPNs
  - https://github.com/oyam/pytorch-DPNs
# license of the model
license: BSD 3-Clause License
# inputs to the model
modality: general
inputs:
  - type: image
    # description of the first input
    description: the input image
    parameters: # type parameters
      element_type: float32
      input_layer: 0
      layout: CHW
      color_mode: RGB
      dimensions: [3, 224, 224]
      mean: [124, 117, 104]
      scale: [59.88, 59.88, 59.88]
outputs:
  - type: classification
    description: the probability
    parameters:
      element_type: float32
model: # specifies model graph and weights resources
  is_archive:
    false # if set, then the base_url is a url to an archive
    # the graph_path and weights_path then denote the
    # file names of the graph and weights within the archive
  graph_path: https://s3.amazonaws.com/store.carml.org/models/onnxruntime/dpn92-imagenet.onnx
  graph_checksum: 8775db63e9a1562465f689521df9d072
  features_path: http://s3.amazonaws.com/store.carml.org/synsets/imagenet/synset.txt
  features_checksum: 4d234b5833aca44928065a180db3016a
preprocess: |
  from torchvision import transforms
  from PIL import Image
  preprocessor = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[124 / 255, 117 / 255, 104 / 255], std=[59.88 / 255, 59.88 / 255, 59.88 / 255])
  ])
  def preprocess(ctx, data):
    img = Image.open(dataset[int(data)]).convert('RGB')
    return preprocessor(img).numpy()
postprocess: |
  from scipy.special import softmax
  def postprocess(ctx, data):
    return softmax(data[0], axis = 1).tolist()
attributes: # extra network attributes
  kind: CNN # the kind of neural network (CNN, RNN, ...)
  training_dataset: ImageNet # dataset used to for training
  manifest_author: Yen-Hsiang Chang
